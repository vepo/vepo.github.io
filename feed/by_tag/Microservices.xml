<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://blog.vepo.dev/feed/by_tag/Microservices.xml" rel="self" type="application/atom+xml" /><link href="https://blog.vepo.dev/" rel="alternate" type="text/html" /><updated>2026-02-21T19:42:20+00:00</updated><id>https://blog.vepo.dev/feed/by_tag/Microservices.xml</id><title type="html">vepo</title><subtitle>Um reposit√≥rio para todos os posts, palestras e tutoriais que j√° fiz. Java, Desenvolvimento de Software e reflex√µes sobre filosofia</subtitle><author><name>{&quot;twitter&quot;=&gt;&quot;vepo&quot;, &quot;linkedin&quot;=&gt;&quot;https://www.linkedin.com/in/victorosorio/&quot;, &quot;picture&quot;=&gt;&quot;/assets/images/me.avif&quot;}</name></author><entry><title type="html">Log Cleanup no Kafka</title><link href="https://blog.vepo.dev/posts/log-cleanup-no-kafka" rel="alternate" type="text/html" title="Log Cleanup no Kafka" /><published>2020-11-27T00:00:00+00:00</published><updated>2020-11-27T00:00:00+00:00</updated><id>https://blog.vepo.dev/posts/16-10-00-log-cleanup-no-kafka</id><content type="html" xml:base="https://blog.vepo.dev/posts/log-cleanup-no-kafka"><![CDATA[<p>Ao ler o livro <a href="https://www.confluent.io/designing-event-driven-systems/">Designing Event-Driven Systems</a>, tive a impress√£o que o Kafka atua exatamente como uma base de dados. Essa √© uma informa√ß√£o falsa. Ele pode atuar como uma base de dados, desde que seja configurado para.</p>

<p>Nesse post vou mostrar algumas configura√ß√µes de t√≥picos que deve ser feitas para que o dado seja persistente e n√£o ef√™mero.</p>

<h1 id="parti√ß√µes-e-segmentos">Parti√ß√µes e Segmentos</h1>

<p>Espero que voc√™ j√° conhe√ßa alguns elementos importantes de um t√≥pico, como Parti√ß√µes e Fator de Replica√ß√£o. Caso n√£o conhe√ßa, leia <a href="https://blog.vepo.dev/posts/anatomia-de-um-topico">Anatomia de um T√≥pico</a> para podermos conhecer basicamente como funciona um t√≥pico.</p>

<p>No post anterior, s√≥ entrei at√© o detalhe do n√∫mero de parti√ß√£o, pois essa √© a parte importante quando falamos de <strong>ordena√ß√£o de mensagens</strong>.</p>

<p>J√° quando falamos de Cleanup, precisamos introduzir Segmentos. Cada parti√ß√£o, √© subdividida em Segmentos. Segmentos cont√©m os dados ordenados sequencialmente (um arquivo de log), assim como a parti√ß√£o. Ao escrever, o Broker escreve apenas ao final do √∫ltimo segmento da parti√ß√£o. Mas os dados s√£o lidos sequencialmente pelos consumers.</p>

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/6r0v1w4vphys98eh76xp.png" alt="Segmentos" /></p>

<p>Se formos fazer um levantamento nas configura√ß√µes de um t√≥pico, podemos ver que muitas das propriedades s√£o referentes n√£o somente ao t√≥pico, mas ao segmento.</p>

<table>
  <thead>
    <tr>
      <th>Propriedade</th>
      <th>Descri√ß√£o</th>
      <th>Valor Padr√£o</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://kafka.apache.org/documentation/#segment.bytes"><code class="language-plaintext highlighter-rouge">segment.bytes</code></a></td>
      <td>Tamanho do arquivo de segmento.</td>
      <td>1073741824 (1 GB)</td>
    </tr>
    <tr>
      <td><a href="https://kafka.apache.org/documentation/#segment.index.bytes"><code class="language-plaintext highlighter-rouge">segment.index.bytes</code></a></td>
      <td>Tamanho do arquivo de index do segmento.</td>
      <td>10485760 (10 MB)</td>
    </tr>
    <tr>
      <td><a href="https://kafka.apache.org/documentation/#segment.jitter.ms"><code class="language-plaintext highlighter-rouge">segment.jitter.ms</code></a></td>
      <td>O jitter aleat√≥rio m√°ximo subtra√≠do do tempo de rolagem do segmento programado para evitar sobrecargas.</td>
      <td>0</td>
    </tr>
    <tr>
      <td><a href="https://kafka.apache.org/documentation/#segment.ms"><code class="language-plaintext highlighter-rouge">segment.ms</code></a></td>
      <td>Idade m√°xima do segmento. O Kafka far√° a rolagem para garantir sua limpeza</td>
      <td>604800000 (7 dias)</td>
    </tr>
  </tbody>
</table>

<p>Todos esses valores tamb√©m podem ser configurados por cluster. A configura√ß√£o de cluster √© usando como padr√£o, caso o valor n√£o seja configurado no T√≥pico.</p>

<table>
  <thead>
    <tr>
      <th>Configura√ß√£o do T√≥pico</th>
      <th>Configura√ß√£o do Broker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">segment.bytes</code></td>
      <td><code class="language-plaintext highlighter-rouge">log.segment.bytes</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">segment.index.bytes</code></td>
      <td><code class="language-plaintext highlighter-rouge">log.index.size.max.bytes</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">segment.jitter.ms</code></td>
      <td><code class="language-plaintext highlighter-rouge">log.roll.jitter.ms</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">segment.ms</code></td>
      <td><code class="language-plaintext highlighter-rouge">log.roll.ms</code></td>
    </tr>
  </tbody>
</table>

<p>Dado os valores de <code class="language-plaintext highlighter-rouge">segmento.ms</code> e <code class="language-plaintext highlighter-rouge">segment.bytes</code>, o Kafka decidir√° quando um segmento ser√° finalizado para que outro seja inicializado.</p>

<p>O arquivo de index, como o nome j√° diz, √© um √≠ndice que mapeia em qual posi√ß√£o do arquivo de offset uma mensagem est√° armazenada, garantindo assim ao Kafka que qualquer mensagem seja lida em tempo constante.</p>

<p>H√° tamb√©m um outro arquivo de index, o <code class="language-plaintext highlighter-rouge">timeindex</code>. Este tem como fun√ß√£o criar um index baseado no timestamp da mensagem.</p>

<h1 id="pol√≠ticas-de-limpeza">Pol√≠ticas de Limpeza</h1>

<p>Mas o que o Kafka faz com mensagens antigas? Isso √© configur√°vel por T√≥pico ou no Cluster.</p>

<p>Essa configura√ß√£o √© muito importante se voc√™ usa seu Cluster como Fonte de Verdade ou caso voc√™ precise fazer um reset de todo pipeline.</p>

<p>Para configurar √© preciso alterar o valor de <code class="language-plaintext highlighter-rouge">cleanup.policy</code> (ou <code class="language-plaintext highlighter-rouge">log.cleanup.policy</code> para o Cluster). Essa propriedade aceita os valores <code class="language-plaintext highlighter-rouge">compact</code> e <code class="language-plaintext highlighter-rouge">delete</code>. Por padr√£o, essas propriedades v√™m como <code class="language-plaintext highlighter-rouge">delete</code>.</p>

<h2 id="delete">Delete</h2>

<p>Quando a pol√≠tica de limpeza selecionada √© delete, o Kafka vai remover o segmento baseado na sua idade ou no tamanho da parti√ß√£o.</p>

<table>
  <thead>
    <tr>
      <th>Propriedade</th>
      <th>Descri√ß√£o</th>
      <th>Valor Padr√£o</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://kafka.apache.org/documentation/#retention.ms"><code class="language-plaintext highlighter-rouge">retention.ms</code></a></td>
      <td>Idade m√°xima de um segmento</td>
      <td>604800000 (7 dias)</td>
    </tr>
    <tr>
      <td><a href="https://kafka.apache.org/documentation/#retention.bytes"><code class="language-plaintext highlighter-rouge">retention.bytes</code></a></td>
      <td>Tamanho m√°ximo da parti√ß√£o</td>
      <td>-1 (desabilitado)</td>
    </tr>
  </tbody>
</table>

<p>Vale lembrar que essas duas propriedades podem tamb√©m ser configuradas por Cluster.</p>

<table>
  <thead>
    <tr>
      <th>Configura√ß√£o do T√≥pico</th>
      <th>Configura√ß√£o do Broker</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">retention.ms</code></td>
      <td><code class="language-plaintext highlighter-rouge">log.retention.ms</code></td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">retention.bytes</code></td>
      <td><code class="language-plaintext highlighter-rouge">log.retention.bytes</code></td>
    </tr>
  </tbody>
</table>

<h2 id="compacta√ß√£o">Compacta√ß√£o</h2>

<p>A compacta√ß√£o do Log vai fazer uma limpeza, mas garantindo que voc√™ ter√° ao menos a √∫ltima mensagem enviada por chave. Assim teremos apenas a √∫ltima informa√ß√£o de cada chave.</p>

<p>A compacta√ß√£o n√£o ir√° alterar os offsets das mensagens, uma mensagem √© imut√°vel. Ir√° apenas remover mensagem com <code class="language-plaintext highlighter-rouge">offset</code> inferior a √∫ltima mensagem de cada chave.</p>

<p>Mensagens anda podem ser recebidas, mesmo depois de removidas, isso √© feito baseado na propriedade <a href="https://kafka.apache.org/documentation/#delete.retention.ms"><code class="language-plaintext highlighter-rouge">delete.retention.ms</code></a>. Ap√≥s esse tempo se esgotar a mensagem n√£o ser√° recebida.</p>

<p>Uma mensagem apagada, significa que novos consumidores n√£o a receber√£o. Consumidores que j√° estejam recebendo mensagens n√£o perceber√£o que o hist√≥rico foi alterado, a n√£o ser que este tenha seu offset reiniciado.</p>

<p>A compacta√ß√£o ocorre quando o segmento √© finalizado.</p>

<h1 id="implica√ß√µes">Implica√ß√µes</h1>

<p>Ao desenvolvedor e arquiteto, uma pergunta deve ser feita. Quais as implica√ß√µes da escolha da pol√≠tica de limpeza?</p>

<p>Um Cluster ter√° suas configura√ß√µes padr√£o, mas cada T√≥pico pode ter sua pr√≥pria configura√ß√£o.</p>

<h2 id="delete-1">Delete</h2>

<p>Ao se escolher por remover mensagens de um T√≥pico, deve-se ter ci√™ncia que novos consumers n√£o receber√£o mensagens antigas. Vamos imaginar que, com os valores padr√µes, a idade m√°xima de uma mensagem ser√° 14 dias. Assim, se um t√≥pico √© considerado fonte de verdade, deve ter os valores de <code class="language-plaintext highlighter-rouge">retention.ms</code> e <code class="language-plaintext highlighter-rouge">retention.bytes</code> configurados corretamente.</p>

<p>Para se calcular o volume de dados armazenado por T√≥pico, √© preciso levar em considera√ß√£o o tamanho m√©dio de uma mensagem, o n√∫mero de mensagens por dia e o tempo de reten√ß√£o de uma mensagem. Essa √© uma informa√ß√£o que o Arquiteto de Software tem que ter, e mesmo que n√£o tenha, deve estimar baseado nas estatisticas da aplica√ß√£o.</p>

<h2 id="compacta√ß√£o-1">Compacta√ß√£o</h2>

<p>Ao se escolher compactar segmentos de um T√≥pico, deve-se ter ci√™ncia que uma mensagem n√£o deve conter apenas uma atualiza√ß√£o de estado, mas a informa√ß√£o completa. Caso haja apenas atualiza√ß√£o de estado, haver√° perca de dados.</p>

<p>Para se calcular o volume de dados armazenado por T√≥pico, √© necess√°rio ter ci√™ncia do n√∫mero de chaves √∫nicas e o tamanho m√©dio da mensagem, e adicionar o tamanho m√°ximo de um segmento.</p>

<h1 id="conclus√£o">Conclus√£o</h1>

<p>Kafka pode ser usado como Fonte de Verdade, mas antes deve-se conhecer a fundo como configurar. As configura√ß√µes padr√£o garantem que uma mensagem ficar√° armazenada por entre 7 e 14 dias, mas isso pode ser alterado de acordo com os requisitos do sistema.</p>

<hr />

<p><img src="https://dev-to-uploads.s3.amazonaws.com/i/1os85b4rmdpauz3yjbsu.jpg" alt="Hard Disk" /></p>

<p>Foto de <strong>Azamat E</strong> no <a href="https://www.pexels.com/pt-br/foto/analogico-analogo-aparelhos-armazenamento-117729/"><strong>Pexels</strong></a>.</p>]]></content><author><name>{&quot;twitter&quot;=&gt;&quot;vepo&quot;, &quot;linkedin&quot;=&gt;&quot;https://www.linkedin.com/in/victorosorio/&quot;, &quot;picture&quot;=&gt;&quot;/assets/images/me.avif&quot;}</name></author><category term="Kafka" /><category term="Apache Kafka" /><category term="Microservices" /><summary type="html"><![CDATA[Como o Kafka limpa as informa√ß√µes antigas? Quais par√¢metros configurar?]]></summary></entry><entry><title type="html">Entendendo o Kafka ‚Äî Uma Introdu√ß√£o √† Plataforma de Eventos</title><link href="https://blog.vepo.dev/posts/entendendo-o-kafka" rel="alternate" type="text/html" title="Entendendo o Kafka ‚Äî Uma Introdu√ß√£o √† Plataforma de Eventos" /><published>2018-04-30T00:00:00+00:00</published><updated>2023-09-25T20:00:00+00:00</updated><id>https://blog.vepo.dev/posts/00-00-00-entendendo-o-kafka</id><content type="html" xml:base="https://blog.vepo.dev/posts/entendendo-o-kafka"><![CDATA[<h1 id="o-que-√©">O que √©?</h1>

<p>O Apache Kafka √© muito mais que um Message Broker open source. Com uma grande comunidade e muita estabilidade possui muito mais funcionalidades do que a simples troca de mensagens entre produtores e consumidores.</p>

<p>Ele √© bem mais complexo que seus similares <strong>RabbitMQ</strong>, <strong>ActiveMQ</strong>, ou o <strong>SQS</strong> da Amazon. Caso voc√™ deseja somente uma troca de mensagens entre servi√ßos, n√£o perca tempo usando o Kafka, h√° outros mais simples.</p>

<p>Por sua grande complexidade, algumas pessoas v√™em o Kafka do ponto de vista limitado ao uso que fizeram. Algumas v√™em como uma API assyncrona, outros como uma base de dados para eventos e outras como um substituto para um Service Bus (ESB). Todos esses uso s√£o usos limitados da plataforma.</p>

<p>O que voc√™ precisa saber √© que, se voc√™ precisa manter mensagens por longos per√≠odos, reprocessar mensagens antigas, baixo acoplamento entre servi√ßos e toler√¢ncia a falhas, ent√£o √© o Kafka que voc√™ procura!</p>

<p>Segundo o livro <a href="https://www.confluent.io/designing-event-driven-systems">Designing Event-Driven System</a>, o Kafka √© uma plataforma de Streaming. H√° APIs de processamento de Stream e APIs para envio e recebimento de dados.</p>

<p><img src="/assets/images/stream-data-platform.webp" alt="Stream Data Platform" /></p>

<p>Voc√™ pode usar o Kafka como uma <a href="https://en.wikipedia.org/wiki/Single_source_of_truth">Fonte da Verdade</a>. Recebendo eventos e dados, processando os dados e construir pipelines de dados e complexas arquiteturas baseadas em eventos e dados.</p>

<h1 id="para-que-usar">Para que usar?</h1>

<p>Caso voc√™ n√£o tenha contato com padr√µes de arquitetura de Microservi√ßos, sugiro ler alguns artigos em <a href="http://microservices.io/">microservices.io</a>. Nos √∫ltimos anos, as aplica√ß√µes web pararam de ser apenas um servidor mon√≥lito tratando todas as requisi√ß√µes sincronamente.</p>

<p>Hoje, uma √∫nica aplica√ß√£o pode se constituida de v√°rios servi√ßos, todos atuando independentemente. O dado agora flui entre os servi√ßos e nenhum deles tem o total controle de um √∫nico dado. S√£o novos padr√µes arquiteturais para satisfazer requisitos como escalabilidade.</p>

<h1 id="arquitetura">Arquitetura</h1>

<p>O Kafka √© um broker que roda em cluster, para sistemas tolerante a falhas, √© aconselh√°vel que seja configurar mais de uma inst√¢ncia. Como √© um cluster, ele roda usando o ZooKeeper para sincronia.</p>

<p>Ele recebe, armazena e distribui records. Um record √© um dado gerado por algum n√≥ do sistema que pode ser um evento ou uma informa√ß√£o. Ele √© enviado para o cluster e o mesmo o armazena em uma partition do t√≥pico.</p>

<p>Cada record possui um offset sequ√™ncia, e o consumer pode controlar o offset que est√° consumindo. Assim, caso h√° a necessidade de se reprocessar o t√≥pico, pode ser feito baseado no offset.</p>

<h1 id="criando-um-cluster-kafka">Criando um cluster Kafka</h1>

<p>Vamos criar um cluster Kafka usando docker? Bom, n√£o √© necess√°rio ‚Äúreescrever‚Äù a roda, j√° temos algumas imagens prontas, vamos usar a do Spotify! E criar uma imagem do Kafka √© um pouco mais complexo do que apenas docker, ele depende do ZooKeeper, mas √© um bom exerc√≠cio de configura√ß√£o.</p>

<p>Antes de come√ßar √© necess√°rio ter instalado:</p>

<ul>
  <li>Docker</li>
  <li>Virtualbox</li>
</ul>

<p>Para isso crie uma <code class="language-plaintext highlighter-rouge">docker-machine</code>:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-machine create <span class="nt">--driver</span> virtualbox kafka-broker
</code></pre></div></div>

<p>Agora que temos uma docker-machine precisamos colocar ela como a ativa:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">eval</span> <span class="si">$(</span>docker-machine <span class="nb">env </span>kafka-broker<span class="si">)</span>
</code></pre></div></div>

<p>Pronto! Agora podemos executar os passos para criar um container usando a imagem do Spotify:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run <span class="nt">-p</span> 2181:2181 <span class="nt">-p</span> 9092:9092 <span class="nt">--env</span> <span class="nv">ADVERTISED_HOST</span><span class="o">=</span><span class="sb">`</span>docker-machine ip <span class="se">\`</span>docker-machine active<span class="se">\`</span><span class="sb">`</span> <span class="nt">--env</span> <span class="nv">ADVERTISED_PORT</span><span class="o">=</span>9092 spotify/kafka
</code></pre></div></div>

<p>Sucesso! Agora temos um cluster Kafka rodando dentro de uma docker machine. Para saber qual o IP dela, basta executar:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-machine ip kafka-broker
</code></pre></div></div>

<p>O comando acima retornar√° um IP, que deve ser usado como nosso broker. Para se usar os exemplos abaixo, substitua <em>localhost</em> pelo IP.</p>

<h1 id="produzindo-mensagens">Produzindo Mensagens</h1>

<p>A produ√ß√£o de mensagens no Kafka √© mais simples que o consumo. Uma mensagem √© produzida e enviada para um T√≥pico. N√£o √© preciso especificar um schema para mensagem, a √∫nica preocupa√ß√£o entre produtor e consumidor √© como ela ser√° Serializada.</p>

<p>Sistemas mais antigos usavam XML, mas o tanto de dados gerados √© muito grande para pouca informa√ß√£o. Hoje √© muito usado o formato JSON, que √© de f√°cil leitura humana e gera mensagens menores do que se usarmos XML. Uma boa dica √© usar <a href="https://github.com/google/protobuf">Protobuf</a>, este gera mensagens mais compactas e pode haver suporte a altera√ß√µes de <em>schemas</em>.</p>

<p>Para o produtor, voc√™ pode serializar suas mensagens em ByteArray e enviar, no exemplo abaixo usaremos o meio mais simples, apenas o envio de String.</p>

<div data-gist="https://gist.github.com/vepo/ddd1afc55d38165b61eab83371723541"></div>

<h1 id="consumindo-mensagens">Consumindo Mensagens</h1>

<p>Como j√° disse anteriormente, para consumir uma mensagem sua √∫nica preocupa√ß√£o tem que ser a Serializa√ß√£o de dados. Esse √© o maior contrato entre produtor e consumidor no Kafka.</p>

<p>O Kafka garante que todas as mensagens somente ser√£o consumidas uma vez por cliente. Isso significa, se eu enviar uma mensagem para um t√≥pico X, e tiver 1000 consumidores com o Client ID Y, somente um vai processar essa mensagem. Isso garante um bom desacoplamento e f√°cil escalabilidade. Voc√™ pode delegar toda a sincronicidade do processamento para o Kafka.</p>

<p>Para que uma mensagem seja consumida por dois consumidores diferentes, s√≥ usar dois client ID diferentes.</p>

<div data-gist="https://gist.github.com/vepo/b63ff8384941329485266999f99e2264"></div>

<h1 id="outras-funcionalidades">Outras funcionalidades</h1>

<p>O Kafka permite usar os t√≥picos como tabelas, permitindo fazer <em>queries</em> para aquisi√ß√£o de dados, isso pode ser usado para uma arquitetura baseada em Eventos.</p>

<p>Essa funcionalidade por√©m n√£o √© t√£o simples como √© descrito na documenta√ß√£o. A serializa√ß√£o √© um grande impeditivo e em muitos momentos o stream ‚Äú<em>se perde</em>‚Äù. Acredito que essa feature s√≥ √© recomendada quando:</p>

<ul>
  <li>Os dados s√£o apenas incrementais</li>
  <li>Os dados n√£o s√£o relacionais</li>
  <li>Os dados s√£o sequ√™nciais</li>
</ul>

<h1 id="ordena√ß√£o-das-mensagens">Ordena√ß√£o das mensagens</h1>

<p>O Kafka permite que as mensagens sejam processadas em ordem, isso √© habilitado com a configura√ß√£o do n√∫mero de parti√ß√µes de um mesmo t√≥pico</p>

<p>Para maiores detalhes veja o post <a href="https://blog.vepo.dev/posts/ordenacao-no-kafka">Ordena√ß√£o no Kafka</a>.</p>

<h1 id="conclus√£o">Conclus√£o</h1>

<p>Kafka √© o middleware mais robusto no mercado para atuar se criar uma arquitetura baseada em Eventos.</p>

<p>F√°cil de se usar, d√° para se construir uma arquitetura baseada em eventos na qual cada novas funcionalidades podem ser plugadas, desplugadas e atualizadas sem a necessidade de deploys em todos os servi√ßos.</p>

<p>Seu backend pode se preocupar com o m√≠nimo para um r√°pido processamento, criando pipelines ass√≠ncronas complexas. Assim, um webcomerce pode finalizar a compra e apenas enviando uma mensagem disparar outras a√ß√µes como Nota Fiscal, Estoque, E-mail, etc‚Ä¶</p>]]></content><author><name>{&quot;twitter&quot;=&gt;&quot;vepo&quot;, &quot;linkedin&quot;=&gt;&quot;https://www.linkedin.com/in/victorosorio/&quot;, &quot;picture&quot;=&gt;&quot;/assets/images/me.avif&quot;}</name></author><category term="Apache Kafka" /><category term="Message Broker" /><category term="Microsservi√ßos" /><category term="Pub/Sub" /><category term="Arquitetura Orientada a Eventos" /><category term="Data Stream Processing" /><category term="Java" /><category term="Microservices" /><summary type="html"><![CDATA[Descubra como o Apache Kafka vai al√©m de um simples message broker e se torna a base ideal para arquiteturas orientadas a eventos e microsservi√ßos. Neste guia introdut√≥rio, voc√™ vai aprender: - O que √© o Kafka e quando us√°-lo (ou n√£o) em compara√ß√£o com RabbitMQ, ActiveMQ e Amazon SQS; - Como ele atua como uma plataforma de streaming completa, permitindo reprocessamento, baixo acoplamento e alta toler√¢ncia a falhas; - Passo a passo para criar um cluster Kafka com Docker; - Exemplos pr√°ticos de produ√ß√£o e consumo de mensagens; - Como garantir a ordena√ß√£o das mensagens e usar t√≥picos como fontes da verdade. Ideal para desenvolvedores e arquitetos que buscam escalabilidade, resili√™ncia e flexibilidade em sistemas distribu√≠dos. üöÄ]]></summary></entry></feed>