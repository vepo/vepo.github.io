---
title: Entendendo o Kafka ‚Äî Uma Introdu√ß√£o √† Plataforma de Eventos
permalink: /posts/entendendo-o-kafka
published: true
description: |
    Descubra como o Apache Kafka vai al√©m de um simples message broker e se torna a base ideal para arquiteturas orientadas a eventos e microsservi√ßos. Neste guia introdut√≥rio, voc√™ vai aprender:
    
        O que √© o Kafka e quando us√°-lo (ou n√£o) em compara√ß√£o com RabbitMQ, ActiveMQ e Amazon SQS;
    
        Como ele atua como uma plataforma de streaming completa, permitindo reprocessamento, baixo acoplamento e alta toler√¢ncia a falhas;
    
        Passo a passo para criar um cluster Kafka com Docker;
    
        Exemplos pr√°ticos de produ√ß√£o e consumo de mensagens;
    
        Como garantir a ordena√ß√£o das mensagens e usar t√≥picos como fontes da verdade.
    
    Ideal para desenvolvedores e arquitetos que buscam escalabilidade, resili√™ncia e flexibilidade em sistemas distribu√≠dos. üöÄ
tags: [Apache Kafka, Message Broker, Microsservi√ßos, Pub/Sub, Arquitetura Orientada a Eventos, Data Stream Processing, Java, Microservices]
cover_image: /assets/images/rio-fluindo-100-42.webp
publish_date: 2018-04-30 12:00:00 +0300
last_modified_at: 2023-09-25 23:00:00 +0300
original: "https://medium.com/@vepo/entendendo-o-kafka-bf64169e421f"
---

# O que √©?

O Apache Kafka √© muito mais que um Message Broker open source. Com uma grande comunidade e muita estabilidade possui muito mais funcionalidades do que a simples troca de mensagens entre produtores e consumidores.

Ele √© bem mais complexo que seus similares **RabbitMQ**, **ActiveMQ**, ou o **SQS** da Amazon. Caso voc√™ deseja somente uma troca de mensagens entre servi√ßos, n√£o perca tempo usando o Kafka, h√° outros mais simples.

Por sua grande complexidade, algumas pessoas v√™em o Kafka do ponto de vista limitado ao uso que fizeram. Algumas v√™em como uma API assyncrona, outros como uma base de dados para eventos e outras como um substituto para um Service Bus (ESB). Todos esses uso s√£o usos limitados da plataforma.

O que voc√™ precisa saber √© que, se voc√™ precisa manter mensagens por longos per√≠odos, reprocessar mensagens antigas, baixo acoplamento entre servi√ßos e toler√¢ncia a falhas, ent√£o √© o Kafka que voc√™ procura!

Segundo o livro [Designing Event-Driven System](https://www.confluent.io/designing-event-driven-systems), o Kafka √© uma plataforma de Streaming. H√° APIs de processamento de Stream e APIs para envio e recebimento de dados.

![Stream Data Platform](/assets/images/stream-data-platform.webp)

Voc√™ pode usar o Kafka como uma [Fonte da Verdade](https://en.wikipedia.org/wiki/Single_source_of_truth). Recebendo eventos e dados, processando os dados e construir pipelines de dados e complexas arquiteturas baseadas em eventos e dados.

# Para que usar?

Caso voc√™ n√£o tenha contato com padr√µes de arquitetura de Microservi√ßos, sugiro ler alguns artigos em [microservices.io](http://microservices.io/). Nos √∫ltimos anos, as aplica√ß√µes web pararam de ser apenas um servidor mon√≥lito tratando todas as requisi√ß√µes sincronamente.

Hoje, uma √∫nica aplica√ß√£o pode se constituida de v√°rios servi√ßos, todos atuando independentemente. O dado agora flui entre os servi√ßos e nenhum deles tem o total controle de um √∫nico dado. S√£o novos padr√µes arquiteturais para satisfazer requisitos como escalabilidade.

# Arquitetura

O Kafka √© um broker que roda em cluster, para sistemas tolerante a falhas, √© aconselh√°vel que seja configurar mais de uma inst√¢ncia. Como √© um cluster, ele roda usando o ZooKeeper para sincronia.

Ele recebe, armazena e distribui records. Um record √© um dado gerado por algum n√≥ do sistema que pode ser um evento ou uma informa√ß√£o. Ele √© enviado para o cluster e o mesmo o armazena em uma partition do t√≥pico.

Cada record possui um offset sequ√™ncia, e o consumer pode controlar o offset que est√° consumindo. Assim, caso h√° a necessidade de se reprocessar o t√≥pico, pode ser feito baseado no offset.

# Criando um cluster Kafka

Vamos criar um cluster Kafka usando docker? Bom, n√£o √© necess√°rio "reescrever" a roda, j√° temos algumas imagens prontas, vamos usar a do Spotify! E criar uma imagem do Kafka √© um pouco mais complexo do que apenas docker, ele depende do ZooKeeper, mas √© um bom exerc√≠cio de configura√ß√£o.

Antes de come√ßar √© necess√°rio ter instalado:

* Docker
* Virtualbox

Para isso crie uma `docker-machine`:

```bash
docker-machine create --driver virtualbox kafka-broker
```

Agora que temos uma docker-machine precisamos colocar ela como a ativa:

```bash
eval $(docker-machine env kafka-broker)
```

Pronto! Agora podemos executar os passos para criar um container usando a imagem do Spotify:

```bash
docker run -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=`docker-machine ip \`docker-machine active\`` --env ADVERTISED_PORT=9092 spotify/kafka
```

Sucesso! Agora temos um cluster Kafka rodando dentro de uma docker machine. Para saber qual o IP dela, basta executar:

```bash
docker-machine ip kafka-broker
```

O comando acima retornar√° um IP, que deve ser usado como nosso broker. Para se usar os exemplos abaixo, substitua _localhost_ pelo IP.

# Produzindo Mensagens

A produ√ß√£o de mensagens no Kafka √© mais simples que o consumo. Uma mensagem √© produzida e enviada para um T√≥pico. N√£o √© preciso especificar um schema para mensagem, a √∫nica preocupa√ß√£o entre produtor e consumidor √© como ela ser√° Serializada.

Sistemas mais antigos usavam XML, mas o tanto de dados gerados √© muito grande para pouca informa√ß√£o. Hoje √© muito usado o formato JSON, que √© de f√°cil leitura humana e gera mensagens menores do que se usarmos XML. Uma boa dica √© usar [Protobuf](https://github.com/google/protobuf), este gera mensagens mais compactas e pode haver suporte a altera√ß√µes de _schemas_.

Para o produtor, voc√™ pode serializar suas mensagens em ByteArray e enviar, no exemplo abaixo usaremos o meio mais simples, apenas o envio de String.

{% gist https://gist.github.com/vepo/ddd1afc55d38165b61eab83371723541 %}


# Consumindo Mensagens

Como j√° disse anteriormente, para consumir uma mensagem sua √∫nica preocupa√ß√£o tem que ser a Serializa√ß√£o de dados. Esse √© o maior contrato entre produtor e consumidor no Kafka.

O Kafka garante que todas as mensagens somente ser√£o consumidas uma vez por cliente. Isso significa, se eu enviar uma mensagem para um t√≥pico X, e tiver 1000 consumidores com o Client ID Y, somente um vai processar essa mensagem. Isso garante um bom desacoplamento e f√°cil escalabilidade. Voc√™ pode delegar toda a sincronicidade do processamento para o Kafka.

Para que uma mensagem seja consumida por dois consumidores diferentes, s√≥ usar dois client ID diferentes.

{% gist https://gist.github.com/vepo/b63ff8384941329485266999f99e2264 %}

# Outras funcionalidades

O Kafka permite usar os t√≥picos como tabelas, permitindo fazer _queries_ para aquisi√ß√£o de dados, isso pode ser usado para uma arquitetura baseada em Eventos.

Essa funcionalidade por√©m n√£o √© t√£o simples como √© descrito na documenta√ß√£o. A serializa√ß√£o √© um grande impeditivo e em muitos momentos o stream "_se perde_". Acredito que essa feature s√≥ √© recomendada quando:

* Os dados s√£o apenas incrementais
* Os dados n√£o s√£o relacionais
* Os dados s√£o sequ√™nciais

# Ordena√ß√£o das mensagens

O Kafka permite que as mensagens sejam processadas em ordem, isso √© habilitado com a configura√ß√£o do n√∫mero de parti√ß√µes de um mesmo t√≥pico

Para maiores detalhes veja o post [Ordena√ß√£o no Kafka](https://blog.vepo.dev/posts/ordenacao-no-kafka).

# Conclus√£o

Kafka √© o middleware mais robusto no mercado para atuar se criar uma arquitetura baseada em Eventos.

F√°cil de se usar, d√° para se construir uma arquitetura baseada em eventos na qual cada novas funcionalidades podem ser plugadas, desplugadas e atualizadas sem a necessidade de deploys em todos os servi√ßos.

Seu backend pode se preocupar com o m√≠nimo para um r√°pido processamento, criando pipelines ass√≠ncronas complexas. Assim, um webcomerce pode finalizar a compra e apenas enviando uma mensagem disparar outras a√ß√µes como Nota Fiscal, Estoque, E-mail, etc‚Ä¶